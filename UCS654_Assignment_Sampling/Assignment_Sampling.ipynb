{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w4JX2u3eFqX",
        "outputId": "80582cea-a831-432b-d8c9-0fb5f380b24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Original class distribution:\")\n",
        "print(df['Class'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Oversampling Technique:using SMOTE\n",
        "\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, Y_balanced = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "balanced_df = pd.DataFrame(X_balanced)\n",
        "balanced_df['Class'] = Y_balanced\n",
        "\n",
        "print(\"\\nBalanced class distribution:\")\n",
        "print(balanced_df['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlHkfVnlLKS",
        "outputId": "6bbe3404-4f09-4834-881b-78192d796360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Balanced class distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create Sampling Techniques\n",
        "\n",
        "\n",
        "def simple_random_sampling(df, n):\n",
        "    return df.sample(n=n, random_state=42)\n",
        "\n",
        "def systematic_sampling(df, k=5):\n",
        "    return df.iloc[::k]\n",
        "\n",
        "def stratified_sampling(df, n):\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    split = StratifiedShuffleSplit(n_splits=1, train_size=n, random_state=42)\n",
        "    for train_idx, _ in split.split(df, df['Class']):\n",
        "        return df.iloc[train_idx]\n",
        "\n",
        "def cluster_sampling(df, n_clusters=5):\n",
        "    df_copy = df.copy()\n",
        "    df_copy['cluster'] = pd.qcut(df_copy.index, n_clusters, labels=False)\n",
        "    chosen_cluster = np.random.choice(df_copy['cluster'].unique())\n",
        "    return df_copy[df_copy['cluster'] == chosen_cluster].drop(\"cluster\", axis=1)\n",
        "\n",
        "def bootstrap_sampling(df, n):\n",
        "    return df.sample(n=n, replace=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "Ou-eH2F5lQEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 5 samples\n",
        "sample_size = 1000\n",
        "\n",
        "S1 = simple_random_sampling(balanced_df, sample_size)\n",
        "S2 = systematic_sampling(balanced_df)\n",
        "S3 = stratified_sampling(balanced_df, sample_size)\n",
        "S4 = cluster_sampling(balanced_df)\n",
        "S5 = bootstrap_sampling(balanced_df, sample_size)\n",
        "\n",
        "samples = [S1, S2, S3, S4, S5]\n"
      ],
      "metadata": {
        "id": "btxhCTufeXyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 models used\n",
        "models = {\n",
        "    \"M1_Logistic\": LogisticRegression(max_iter=1000),\n",
        "    \"M2_DecisionTree\": DecisionTreeClassifier(),\n",
        "    \"M3_RandomForest\": RandomForestClassifier(),\n",
        "    \"M4_KNN\": KNeighborsClassifier(),\n",
        "    \"M5_SVM\": SVC()\n",
        "}"
      ],
      "metadata": {
        "id": "bBsbb5Dyl00T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-Validation\n",
        "results = pd.DataFrame(index=models.keys(),\n",
        "                       columns=[\"Sampling1\", \"Sampling2\", \"Sampling3\", \"Sampling4\", \"Sampling5\"])\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    X_s = sample.drop(\"Class\", axis=1)\n",
        "    y_s = sample[\"Class\"]\n",
        "\n",
        "    # Check if the sample's target variable has at least two unique classes\n",
        "    if y_s.nunique() < 2:\n",
        "        print(f\"Warning: Sampling{i+1} (created by {samples[i].name if hasattr(samples[i], 'name') else 'a sampling method'}) contains only one class. Skipping cross-validation for this sample.\")\n",
        "        # Fill results with NaN for this sample if it has only one class\n",
        "        for model_name in models.keys():\n",
        "            results.iloc[list(models.keys()).index(model_name), i] = np.nan\n",
        "        continue # Skip to the next sample\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        scores = cross_val_score(model, X_s, y_s, cv=5, scoring=\"accuracy\")\n",
        "        results.iloc[list(models.keys()).index(model_name), i] = round(scores.mean()*100, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSR3-H1hl1F1",
        "outputId": "a6c7cfd1-fb47-4f87-e880-b2e9495162fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Sampling4 (created by a sampling method) contains only one class. Skipping cross-validation for this sample.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the final output\n",
        "print(\"\\nFinal Accuracy Table:\")\n",
        "print(results)\n",
        "\n",
        "print(\"\\nBest sampling technique per model:\")\n",
        "print(results.astype(float).idxmax(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw9KJPN4l7ge",
        "outputId": "d2cfb806-d9fc-4f1a-ce8a-4d95b4ab9456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Accuracy Table:\n",
            "                Sampling1 Sampling2 Sampling3 Sampling4 Sampling5\n",
            "M1_Logistic          91.2      85.3      92.2       NaN      94.2\n",
            "M2_DecisionTree      97.6     86.91      98.4       NaN      98.1\n",
            "M3_RandomForest      99.6     98.04     100.0       NaN      99.3\n",
            "M4_KNN               92.4     78.11      92.6       NaN      92.9\n",
            "M5_SVM               97.7     95.09      97.8       NaN      98.8\n",
            "\n",
            "Best sampling technique per model:\n",
            "M1_Logistic        Sampling5\n",
            "M2_DecisionTree    Sampling3\n",
            "M3_RandomForest    Sampling3\n",
            "M4_KNN             Sampling5\n",
            "M5_SVM             Sampling5\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWz0Y0Y_l_yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}